# Sign-Language-Detection-Model
This model can detect actions and signs from a person and interprets them into words. 

According to the World Federation of the Deaf, there are over 300 sign languages around the world that 70 million deaf people are using them (Murray, 2018). Sign language recognition would help break down the barriers for sign language users in society. Most of the communication technologies have been developed to support spoken or written language (which excludes sign language). While communication technologies and tools such as IMO (Page-bites, 2018) and Whats App (Acton Koum, 2009) have become an important part of our life, deaf people have many problems for using these technologies. Daily communication of the deaf community with the hearing majority community can be facilitated using these technologies. As a result, sign language, as a structural form of the hand gestures involving visual motions and signs, is used as a communication system to help the deaf and speech-impaired community for daily interaction. Sign language involves the usage of different parts of the body, such as fingers, hand, arm, head, body, and facial expression (Cheok, Omar, Jaward,2017). [1] In sign language each gesture has a specific meaning. So, therefore complex meanings can be explain by the help of combination of various basic elements. It is basically a non-verbal language which is usually used to deaf and dumb people to communicate more effectively with each other.
